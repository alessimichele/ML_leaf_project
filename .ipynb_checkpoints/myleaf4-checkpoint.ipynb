{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf5eaed3",
   "metadata": {},
   "source": [
    "## Preparing the dataset\n",
    "- load the data\n",
    "- rename the columns\n",
    "- split the dataset into train and test (test will be used only at the very final step)\n",
    "- separate the independent variables from the target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde6e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the data\n",
    "leaf = pd.read_csv(\"leaf.csv\" , header = None)\n",
    "\n",
    "# rename the columns\n",
    "names = np.array([\"Class\", \"Specimen\", \"Eccentricity\", \"Aspect Ratio\", \"Elongation\",\n",
    "                  \"Solidity\", \"Stochastic Convexity\", \"Isoperimetric Factor\",\n",
    "                  \"Maximal Indentation Depth \",\"Lobedness\",\"Average Intensity\",\n",
    "                  \"Average Contrast\",\"Smoothness\",\"Third moment\",\"Uniformity\",\"Entropy\"])\n",
    "leaf.columns = names\n",
    "\n",
    "data = leaf.loc[:, leaf.columns != 'Specimen']\n",
    "\n",
    "\"\"\"\n",
    "# split the dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, random_state = 5, test_size = 0.2, stratify = data['Class'])\n",
    "train.index = np.linspace(0, len(train)-1, len(train), dtype = 'int')\n",
    "test.index = np.linspace(0, len(test)-1, len(test), dtype = 'int')\n",
    "\n",
    "\n",
    "# separate the independent variables from the target variables\n",
    "X = train.loc[:, train.columns != 'Class']\n",
    "y = train['Class']\n",
    "\"\"\"\n",
    "\n",
    "X = data.loc[:, data.columns != 'Class']\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36c998",
   "metadata": {},
   "source": [
    "## Building some useful tools\n",
    "- declaring two cross-validation loop: \n",
    "    - outer stratified cv-loop\n",
    "    - inner non-stratified cv-loop\n",
    "- set the scoring we'd like to compute (this tuple will be used inside 'do_cross_validation')\n",
    "- definition of do_cross_validation: it evaluate metric(s) by cross-validation and also record fit/score times, then print result(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0e6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score, KFold, LeaveOneOut, cross_validate\n",
    "\n",
    "# declaring two cross-validation loop\n",
    "inner_cv = StratifiedKFold(n_splits = 5) # random_state = 10)\n",
    "outer_cv = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "\n",
    "# set the scoring\n",
    "scoring = ('f1_weighted', 'accuracy', 'f1_macro', 'f1_micro', 'roc_auc_ovo_weighted', 'roc_auc_ovr_weighted')\n",
    "\n",
    "# definition of do_cross_validation\n",
    "def do_cross_validation(clf,X=X, y=y, print_model=True, scoring = scoring):\n",
    "    cv = cross_validate(clf, X, y, scoring=scoring, cv= outer_cv, return_train_score=False)\n",
    "\n",
    "    for i in range(len(scoring)):\n",
    "        scores = ' + '.join(f'{s:.2f}' for s in cv['test_' + scoring[i]])\n",
    "        mean_ = cv['test_' + scoring[i]].mean()\n",
    "        msg = f'Cross-validated {scoring[i]}: ({scores}) / {outer_cv.n_splits} = {mean_:.2f}'\n",
    "        if print_model:\n",
    "            msg = f'{clf}:\\n\\t{msg}\\n'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c399920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001a0b7",
   "metadata": {},
   "source": [
    "## Train RandomForest\n",
    "- train a RandomForest by a two nested CV loop. \n",
    "    - in the outer loop we estimate the score indexes using 'do_cross_validation'\n",
    "    - in the inner loop we to GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "673d580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=RandomForestClassifier(random_state=0), n_jobs=4,\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'n_estimators': [50, 100, 500]}):\n",
      "\tCross-validated f1_weighted: (0.77 + 0.79 + 0.73 + 0.64 + 0.71) / 5 = 0.73\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=RandomForestClassifier(random_state=0), n_jobs=4,\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'n_estimators': [50, 100, 500]}):\n",
      "\tCross-validated accuracy: (0.78 + 0.81 + 0.75 + 0.68 + 0.74) / 5 = 0.75\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=RandomForestClassifier(random_state=0), n_jobs=4,\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'n_estimators': [50, 100, 500]}):\n",
      "\tCross-validated f1_macro: (0.77 + 0.77 + 0.73 + 0.64 + 0.70) / 5 = 0.72\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=RandomForestClassifier(random_state=0), n_jobs=4,\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'n_estimators': [50, 100, 500]}):\n",
      "\tCross-validated f1_micro: (0.78 + 0.81 + 0.75 + 0.68 + 0.74) / 5 = 0.75\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=RandomForestClassifier(random_state=0), n_jobs=4,\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'n_estimators': [50, 100, 500]}):\n",
      "\tCross-validated roc_auc_ovo_weighted: (0.97 + 0.99 + 0.98 + 0.99 + 0.99) / 5 = 0.98\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=RandomForestClassifier(random_state=0), n_jobs=4,\n",
      "             param_grid={'criterion': ['gini', 'entropy'],\n",
      "                         'n_estimators': [50, 100, 500]}):\n",
      "\tCross-validated roc_auc_ovr_weighted: (0.97 + 0.99 + 0.98 + 0.99 + 0.99) / 5 = 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# random forest inner loop\n",
    "param_grid={'n_estimators': [50, 100, 500], 'criterion': [\"gini\", \"entropy\"]}\n",
    "clf_grid = GridSearchCV(RandomForestClassifier(random_state=0), param_grid=param_grid, cv = inner_cv, n_jobs=4)\n",
    "# random forest outer loop\n",
    "do_cross_validation(clf_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113ba18",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "\n",
    "before moving to SVM and kNN, we need to standardize our independent variable. Since we are using cross validation also to assess our final performance metric we need to ensure that standardization is performed in each fold and not on the whole dataset.\\\n",
    "In order to do this we need to use the sklearn `pipeline` in conjunction with nested cross validation as before.\\\n",
    "**Performing standardization on the whole set would be wrong as we'd have information leakage from the data we use to perform our cross validation**\\\n",
    "\n",
    "When you use parameter_grid remember that the parameters must have the name of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c9773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b226f4",
   "metadata": {},
   "source": [
    "## Train SVM with Gaussian Kernel \n",
    "- train a SVM by a two nested CV loop. \n",
    "    - in the outer loop we estimate the score indexes using 'do_cross_validation'\n",
    "    - in the inner loop we to GridSearch\n",
    "\n",
    "Hyper-paramters to consider in the grid search:\n",
    " - `gamma`: use a set of float values, sklearn documentation suggests using exponentially spaced ones (and so do other tutorials).\n",
    " - `C`: use a set of float values, sklearn documentation suggests using exponentially spaced ones (and so do other tutorials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf38c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=SVC(probability=True), n_jobs=4,\n",
      "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
      "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
      "                         'gamma': ['scale', 'auto'],\n",
      "                         'kernel': ['linear', 'rbf']}):\n",
      "\tCross-validated f1_weighted: (0.76 + 0.76 + 0.81 + 0.81 + 0.70) / 5 = 0.77\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=SVC(probability=True), n_jobs=4,\n",
      "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
      "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
      "                         'gamma': ['scale', 'auto'],\n",
      "                         'kernel': ['linear', 'rbf']}):\n",
      "\tCross-validated accuracy: (0.78 + 0.76 + 0.81 + 0.82 + 0.71) / 5 = 0.78\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=SVC(probability=True), n_jobs=4,\n",
      "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
      "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
      "                         'gamma': ['scale', 'auto'],\n",
      "                         'kernel': ['linear', 'rbf']}):\n",
      "\tCross-validated f1_macro: (0.74 + 0.77 + 0.81 + 0.81 + 0.71) / 5 = 0.77\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=SVC(probability=True), n_jobs=4,\n",
      "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
      "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
      "                         'gamma': ['scale', 'auto'],\n",
      "                         'kernel': ['linear', 'rbf']}):\n",
      "\tCross-validated f1_micro: (0.78 + 0.76 + 0.81 + 0.82 + 0.71) / 5 = 0.78\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=SVC(probability=True), n_jobs=4,\n",
      "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
      "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
      "                         'gamma': ['scale', 'auto'],\n",
      "                         'kernel': ['linear', 'rbf']}):\n",
      "\tCross-validated roc_auc_ovo_weighted: (0.99 + 0.99 + 0.99 + 0.99 + 0.98) / 5 = 0.99\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=SVC(probability=True), n_jobs=4,\n",
      "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05,\n",
      "       1.e+06, 1.e+07, 1.e+08, 1.e+09, 1.e+10]),\n",
      "                         'gamma': ['scale', 'auto'],\n",
      "                         'kernel': ['linear', 'rbf']}):\n",
      "\tCross-validated roc_auc_ovr_weighted: (0.99 + 0.99 + 0.99 + 0.99 + 0.98) / 5 = 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "pipeline_SVC = Pipeline([('scaler', StandardScaler()),\n",
    "                        ('classifier', SVC(kernel='rbf', probability = True))]) #If we choose some scoring without probability set probability to FALSE\n",
    "param_grid = {'classifier__C': np.logspace(-2, 5, 8), 'classifier__gamma' : np.logspace(-4, 3, 8)}\n",
    "grid_search = GridSearchCV(pipeline_SVC, param_grid=param_grid, cv = inner_cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2130d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cross_validation(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0720ccb",
   "metadata": {},
   "source": [
    "## Train kNN\n",
    "- train a kNN by a two nested CV loop. \n",
    "    - in the outer loop we estimate the score indexes using 'do_cross_validation'\n",
    "    - in the inner loop we to GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04b375b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [2, 5, 10, 15], 'p': [1, 2]}):\n",
      "\tCross-validated f1_weighted: (0.68 + 0.65 + 0.50 + 0.75 + 0.67) / 5 = 0.65\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [2, 5, 10, 15], 'p': [1, 2]}):\n",
      "\tCross-validated accuracy: (0.71 + 0.68 + 0.54 + 0.76 + 0.68) / 5 = 0.67\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [2, 5, 10, 15], 'p': [1, 2]}):\n",
      "\tCross-validated f1_macro: (0.67 + 0.66 + 0.50 + 0.74 + 0.68) / 5 = 0.65\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [2, 5, 10, 15], 'p': [1, 2]}):\n",
      "\tCross-validated f1_micro: (0.71 + 0.68 + 0.54 + 0.76 + 0.68) / 5 = 0.67\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [2, 5, 10, 15], 'p': [1, 2]}):\n",
      "\tCross-validated roc_auc_ovo_weighted: (0.89 + 0.89 + 0.87 + 0.96 + 0.89) / 5 = 0.90\n",
      "\n",
      "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
      "             estimator=KNeighborsClassifier(),\n",
      "             param_grid={'n_neighbors': [2, 5, 10, 15], 'p': [1, 2]}):\n",
      "\tCross-validated roc_auc_ovr_weighted: (0.89 + 0.88 + 0.87 + 0.96 + 0.89) / 5 = 0.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# kNN inner loop\n",
    "param_grid={'n_neighbors': [2,5,10,15], 'p':[1, 2]}\n",
    "neigh_grid = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv = inner_cv)\n",
    "# kNN outer loop\n",
    "do_cross_validation(neigh_grid, X=X_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d701ad",
   "metadata": {},
   "source": [
    "## First result\n",
    "\n",
    "- From the previous computation, we see that independently from the score index used, the RandomForest is the best. So we train a RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fa843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retraining a RF\n",
    "# probabilmente da togliere\n",
    "\n",
    "parameters = {'n_estimators':[50,100,500], 'criterion': ['gini', 'entropy', 'log_loss'] }\n",
    "clf = GridSearchCV(RandomForestClassifier(), parameters, cv = inner_cv, n_jobs=4)\n",
    "clf.fit(X=X, y=y)\n",
    "tree_model = clf.best_estimator_\n",
    "print(\"Best score reached is:\", clf.best_score_)\n",
    "print (\"Best parameters are:\", clf.best_params_)\n",
    "\n",
    "\n",
    "crit= list(clf.best_params_.values())[0]\n",
    "n_est = list(clf.best_params_.values())[1]\n",
    "\n",
    "tree = RandomForestClassifier(criterion=crit, n_estimators= n_est)\n",
    "tree.fit(X,y)\n",
    "\n",
    "tree.score(X,y)\n",
    "\n",
    "\n",
    "tree.predict(test.loc[:, test.columns != 'Class'])\n",
    "\n",
    "\n",
    "test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ec84c",
   "metadata": {},
   "source": [
    "## Next step (asap)\n",
    "\n",
    "- MICHELE: effectiveness indexes (scegliere quale usare) \n",
    "- ELENA: cross validation: inner outer (probabilmente sara: stratified e il numero dei fold è tale che non abbiamo fold vuoti rispetto a una classe)\n",
    "- SAMUELE: vedere di sistemare la stadardizzazione \n",
    "\n",
    "- scegliere gli iperparametri di:\n",
    "        - ELENA: albero (aggiungere albero singolo all'inizio) + RF (max_features + quanti alberi?) + kNN\n",
    "        - MICHELE: SVM (linear)\n",
    "        - SAMUELE: SVM (gauss)\n",
    "\n",
    "\n",
    "- analisi variabili ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
